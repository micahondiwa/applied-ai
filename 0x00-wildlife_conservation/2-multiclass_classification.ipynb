{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Multiclass Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from torch.utils.data import dataloader, random_split\n",
    "from torchinfo import summary\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platform: win32\n",
      "Python version: 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)]\n",
      "---\n",
      "matplotlib version: 3.8.3\n",
      "pandas version: 2.2.0\n",
      "PIL version: 10.2.0\n",
      "torch version: 2.5.1+cpu\n",
      "torchvision version: 0.20.1+cpu\n"
     ]
    }
   ],
   "source": [
    "print(\"Platform:\", sys.platform)\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"---\")\n",
    "print(\"matplotlib version:\", matplotlib.__version__)\n",
    "print(\"pandas version:\", pd.__version__)\n",
    "print(\"PIL version:\", PIL.__version__)\n",
    "print(\"torch version:\", torch.__version__)\n",
    "print(\"torchvision version:\", torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Using {device} device.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project Goal**: To build and train a convolutional neural network, and use it to get predictions for the animal classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objectives**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read in data with multiple classes.\n",
    "- Normalize data to improve performance.\n",
    "- Create a CNN that works well with images.\n",
    "- Train that network to do multiclass classification.\n",
    "- Reformat the network predictions to complete the [competition](https://www.drivendata.org/competitions/87/competition-image-classification-wildlife-conservation/). - The goal of the competition is to build a model that takes an image and classifies what animal is in it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Reading Files**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Converting any grayscale images to RGB format with a custom class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvertToRGB:\n",
    "    def __call__(self, img):\n",
    "        if img.mode != \"RGB\":\n",
    "            img = img.convert(\"RGB\")\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using transformers to resize the images, and converting the images to a Tensor of pixel values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        ConvertToRGB(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will read data from data_p1/data_multiclass\\train\n"
     ]
    }
   ],
   "source": [
    "data_dir = (\"data_p1/data_multiclass\")\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "\n",
    "print(\"Will read data from\", train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(root=train_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 6050\n",
      "    Root location: data_p1/data_multiclass\\train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               <__main__.ConvertToRGB object at 0x00000248182EC290>\n",
      "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
