{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image as data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goals**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check tensor attributes: size, data types and device\n",
    "- Manipulate tensors through slicing \n",
    "- Perform mathematical operations with tensors, including matrix manipulation and aggregation calculations.\n",
    "- Downlaod and decompress the dataset.\n",
    "- Load and explore images using PIL.\n",
    "- Demonstrate how visual information is stored in tensors, focusing on color channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import PIL \n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platform: win32\n",
      "Python version: 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)]\n",
      "---\n",
      "matplotlib version: 3.9.2\n",
      "pandas version: 2.2.3\n",
      "PIL version: 11.0.0\n",
      "torch version: 2.5.1+cpu\n",
      "torchvision version: 0.20.1+cpu\n"
     ]
    }
   ],
   "source": [
    "print(\"Platform:\", sys.platform)\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"---\")\n",
    "print(\"matplotlib version:\", matplotlib.__version__)\n",
    "print(\"pandas version:\", pd.__version__)\n",
    "print(\"PIL version:\", PIL.__version__)\n",
    "print(\"torch version:\", torch.__version__)\n",
    "print(\"torchvision version:\", torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Working with Tensors in PyTorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_tensor class: <class 'torch.Tensor'>\n",
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# Creating a nested tensor\n",
    "my_values = [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]\n",
    "my_tensor = torch.Tensor(my_values)\n",
    "\n",
    "print(\"my_tensor class:\", type(my_tensor))\n",
    "print(my_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensor Attributes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_tensor shape:  torch.Size([4, 3])\n",
      "my_tensor data type: torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Printing the dimensions and data type of my_tensor\n",
    "\n",
    "print(\"my_tensor shape: \", my_tensor.shape)\n",
    "print(\"my_tensor data type:\", my_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_tensor device cpu\n"
     ]
    }
   ],
   "source": [
    "# Tensor device attribute\n",
    "\n",
    "print(\"my_tensor device\", my_tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda GPUs available: False\n",
      "mps GPUs available: False\n"
     ]
    }
   ],
   "source": [
    "# Tensor device change\n",
    "\n",
    "# Check if GPUs avaialbale via 'cuda'\n",
    "cuda_gpus_available = torch.cuda.is_available()\n",
    "\n",
    "# Check if GPUs available via 'mps'\n",
    "mps_gpus_available = torch.backends.mps.is_available()\n",
    "\n",
    "print(\"cuda GPUs available:\", cuda_gpus_available)\n",
    "print(\"mps GPUs available:\", mps_gpus_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming gpu was available:\n",
    "\n",
    "# my_tensor = my_tensor.to(\"cuda\")\n",
    "\n",
    "# print(\"my_tensor device:\", my_tensor.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Slicing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
