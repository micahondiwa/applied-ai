{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image as data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goals**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check tensor attributes: size, data types and device\n",
    "- Manipulate tensors through slicing \n",
    "- Perform mathematical operations with tensors, including matrix manipulation and aggregation calculations.\n",
    "- Downlaod and decompress the dataset.\n",
    "- Load and explore images using PIL.\n",
    "- Demonstrate how visual information is stored in tensors, focusing on color channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import PIL \n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platform: win32\n",
      "Python version: 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)]\n",
      "---\n",
      "matplotlib version: 3.9.2\n",
      "pandas version: 2.2.3\n",
      "PIL version: 11.0.0\n",
      "torch version: 2.5.1+cpu\n",
      "torchvision version: 0.20.1+cpu\n"
     ]
    }
   ],
   "source": [
    "print(\"Platform:\", sys.platform)\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"---\")\n",
    "print(\"matplotlib version:\", matplotlib.__version__)\n",
    "print(\"pandas version:\", pd.__version__)\n",
    "print(\"PIL version:\", PIL.__version__)\n",
    "print(\"torch version:\", torch.__version__)\n",
    "print(\"torchvision version:\", torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Working with Tensors in PyTorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "not a sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Creating a nested tensor\u001b[39;00m\n\u001b[0;32m      2\u001b[0m my_values \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m], [\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m], [\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m9\u001b[39m], \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m12\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m my_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_values\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: not a sequence"
     ]
    }
   ],
   "source": [
    "# Creating a nested tensor\n",
    "my_values = [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]\n",
    "my_tensor = torch.Tensor(my_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
