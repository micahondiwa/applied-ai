{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image as data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goals**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check tensor attributes: size, data types and device\n",
    "- Manipulate tensors through slicing \n",
    "- Perform mathematical operations with tensors, including matrix manipulation and aggregation calculations.\n",
    "- Downlaod and decompress the dataset.\n",
    "- Load and explore images using PIL.\n",
    "- Demonstrate how visual information is stored in tensors, focusing on color channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import PIL \n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platform: win32\n",
      "Python version: 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)]\n",
      "---\n",
      "matplotlib version: 3.9.2\n",
      "pandas version: 2.2.3\n",
      "PIL version: 11.0.0\n",
      "torch version: 2.5.1+cpu\n",
      "torchvision version: 0.20.1+cpu\n"
     ]
    }
   ],
   "source": [
    "print(\"Platform:\", sys.platform)\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"---\")\n",
    "print(\"matplotlib version:\", matplotlib.__version__)\n",
    "print(\"pandas version:\", pd.__version__)\n",
    "print(\"PIL version:\", PIL.__version__)\n",
    "print(\"torch version:\", torch.__version__)\n",
    "print(\"torchvision version:\", torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Working with Tensors in PyTorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_tensor class: <class 'torch.Tensor'>\n",
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# Creating a nested tensor\n",
    "my_values = [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]\n",
    "my_tensor = torch.Tensor(my_values)\n",
    "\n",
    "print(\"my_tensor class:\", type(my_tensor))\n",
    "print(my_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensor Attributes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_tensor shape:  torch.Size([4, 3])\n",
      "my_tensor data type: torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Printing the dimensions and data type of my_tensor\n",
    "\n",
    "print(\"my_tensor shape: \", my_tensor.shape)\n",
    "print(\"my_tensor data type:\", my_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_tensor device cpu\n"
     ]
    }
   ],
   "source": [
    "# Tensor device attribute\n",
    "\n",
    "print(\"my_tensor device\", my_tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda GPUs available: False\n",
      "mps GPUs available: False\n"
     ]
    }
   ],
   "source": [
    "# Tensor device change\n",
    "\n",
    "# Check if GPUs avaialbale via 'cuda'\n",
    "cuda_gpus_available = torch.cuda.is_available()\n",
    "\n",
    "# Check if GPUs available via 'mps'\n",
    "mps_gpus_available = torch.backends.mps.is_available()\n",
    "\n",
    "print(\"cuda GPUs available:\", cuda_gpus_available)\n",
    "print(\"mps GPUs available:\", mps_gpus_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming gpu was available:\n",
    "\n",
    "# my_tensor = my_tensor.to(\"cuda\")\n",
    "\n",
    "# print(\"my_tensor device:\", my_tensor.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensor Slicing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_tensor class: <class 'torch.Tensor'>\n",
      "left_tensor shape: torch.Size([2, 3])\n",
      "left_tensor data type: torch.float32\n",
      "left_tensor device: cpu\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n",
      "right_tensor class: <class 'torch.Tensor'>\n",
      "right_tensor shape: torch.Size([2, 3])\n",
      "right_tensor data type: torch.float32\n",
      "right_tensor device: cpu\n",
      "tensor([[ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# Slicing my_tensor into two rows: left_tensor for the top two rows and right_tensor for the bottom two rows\n",
    "left_tensor = my_tensor[:2,:]\n",
    "right_tensor = my_tensor[2:,: ]\n",
    "\n",
    "print(\"left_tensor class:\", type(left_tensor))\n",
    "print(\"left_tensor shape:\", left_tensor.shape)\n",
    "print(\"left_tensor data type:\", left_tensor.dtype)\n",
    "print(\"left_tensor device:\", left_tensor.device)\n",
    "print(left_tensor)\n",
    "print()\n",
    "print(\"right_tensor class:\", type(right_tensor))\n",
    "print(\"right_tensor shape:\", right_tensor.shape)\n",
    "print(\"right_tensor data type:\", right_tensor.dtype)\n",
    "print(\"right_tensor device:\", right_tensor.device)\n",
    "print(right_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensor Math**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summed_tensor_operator class: <class 'torch.Tensor'>\n",
      "summed_tensor_operator shape: torch.Size([2, 3])\n",
      "summed_tensor_operator data type: torch.float32\n",
      "summed_tensor_operator device: cpu\n",
      "tensor([[ 8., 10., 12.],\n",
      "        [14., 16., 18.]])\n",
      "\n",
      "summed_tensor_method class: <class 'torch.Tensor'>\n",
      "summed_tensor_method shape: torch.Size([2, 3])\n",
      "summed_tensor_method data type: torch.float32\n",
      "summed_tensor_method device: cpu\n",
      "tensor([[ 8., 10., 12.],\n",
      "        [14., 16., 18.]])\n"
     ]
    }
   ],
   "source": [
    "# Using both the mathematical operator and the class method to add left_tensor to right_tensor. \n",
    "# Assigning results to summed_tensor_operator and summed_tensor_method\n",
    "\n",
    "summed_tensor_operator = left_tensor + right_tensor\n",
    "summed_tensor_method = left_tensor.add(right_tensor)\n",
    "\n",
    "print(\"summed_tensor_operator class:\", type(summed_tensor_operator))\n",
    "print(\"summed_tensor_operator shape:\", summed_tensor_operator.shape)\n",
    "print(\"summed_tensor_operator data type:\", summed_tensor_operator.dtype)\n",
    "print(\"summed_tensor_operator device:\", summed_tensor_operator.device)\n",
    "print(summed_tensor_operator)\n",
    "print()\n",
    "print(\"summed_tensor_method class:\", type(summed_tensor_method))\n",
    "print(\"summed_tensor_method shape:\", summed_tensor_method.shape)\n",
    "print(\"summed_tensor_method data type:\", summed_tensor_method.dtype)\n",
    "print(\"summed_tensor_method device:\", summed_tensor_method.device)\n",
    "print(summed_tensor_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ew_tensor_operator class: <class 'torch.Tensor'>\n",
      "ew_tensor_operator shape: torch.Size([2, 3])\n",
      "ew_tensor_operator data type: torch.float32\n",
      "ew_tensor_operator device: cpu\n",
      "tensor([[ 7., 16., 27.],\n",
      "        [40., 55., 72.]])\n",
      "\n",
      "ew_tensor_method class: <class 'torch.Tensor'>\n",
      "ew_tensor_method shape: torch.Size([2, 3])\n",
      "ew_tensor_method data type: torch.float32\n",
      "ew_tensor_method device: cpu\n",
      "tensor([[ 7., 16., 27.],\n",
      "        [40., 55., 72.]])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise multiplication\n",
    "\n",
    "ew_tensor_operator = left_tensor * right_tensor\n",
    "ew_tensor_method = left_tensor.mul(right_tensor)\n",
    "\n",
    "print(\"ew_tensor_operator class:\", type(ew_tensor_operator))\n",
    "print(\"ew_tensor_operator shape:\", ew_tensor_operator.shape)\n",
    "print(\"ew_tensor_operator data type:\", ew_tensor_operator.dtype)\n",
    "print(\"ew_tensor_operator device:\", ew_tensor_operator.device)\n",
    "print(ew_tensor_operator)\n",
    "print()\n",
    "print(\"ew_tensor_method class:\", type(ew_tensor_method))\n",
    "print(\"ew_tensor_method shape:\", ew_tensor_method.shape)\n",
    "print(\"ew_tensor_method data type:\", ew_tensor_method.dtype)\n",
    "print(\"ew_tensor_method device:\", ew_tensor_method.device)\n",
    "print(ew_tensor_method)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
