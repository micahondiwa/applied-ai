{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Multiclass Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal**: Using images of crop diseases from Uganda to build a convolutional neural network and train it to classify images into one of the five classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objectives**\n",
    "- Convert images from grayscale to RGB\n",
    "- Resize images \n",
    "- Normalize data\n",
    "- Create a transformation pipeline to standardize images for training\n",
    "- create a Convolutional Neural Network\n",
    "- Train the network to do multiclass classification\n",
    "- Identify overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd \n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import PIL \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torchinfo \n",
    "import torchvision \n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from torch.utils.data import DataLoader, random_split \n",
    "from torchinfo import summary \n",
    "from torchvision import datasets, transforms \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version :  2.5.1+cpu\n",
      "torchvision version :  0.20.1+cpu\n",
      "torchinfo version :  1.8.0\n",
      "numpy version :  1.26.3\n",
      "matplotlib version :  3.8.3\n",
      "PIL version :  10.2.0\n",
      "Python 3.12.1\n"
     ]
    }
   ],
   "source": [
    "print(\"torch version : \", torch.__version__)\n",
    "print(\"torchvision version : \", torchvision.__version__)\n",
    "print(\"torchinfo version : \", torchinfo.__version__)\n",
    "print(\"numpy version : \", np.__version__)\n",
    "print(\"matplotlib version : \", matplotlib.__version__)\n",
    "print(\"PIL version : \", PIL.__version__)\n",
    "\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Using {device} device.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Exploring Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Directory: data_p2\\data_undersampled\n",
      "Training Data Directory: data_p2\\data_undersampled\\train\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(\"data_p2\", \"data_undersampled\")\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "\n",
    "print(\"Data Directory:\", data_dir)\n",
    "print(\"Training Data Directory:\", train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of class names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of classes: ['cassava-bacterial-blight-cbb', 'cassava-brown-streak-disease-cbsd', 'cassava-green-mottle-cgm', 'cassava-healthy', 'cassava-mosaic-disease-cmd']\n"
     ]
    }
   ],
   "source": [
    "classes = os.listdir(train_dir)\n",
    "\n",
    "print(\"List of classes:\", classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvertToRGB:\n",
    "    def __call__(self, img):\n",
    "        if img.mode != \"RGB\":\n",
    "            img = img.convert(\"RGB\")\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.transforms.transforms.Compose'>\n",
      "-----------------\n",
      "Compose(\n",
      "    <__main__.ConvertToRGB object at 0x00000181FBA3B3E0>\n",
      "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.4326, 0.4953, 0.312], std=[0.2178, 0.2214, 0.2091])\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define transformation to apply to the images\n",
    "transform_normalized = transforms.Compose(\n",
    "    [\n",
    "        ConvertToRGB(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        # Convert images to tensors\n",
    "        transforms.ToTensor(),\n",
    "        # Normalize the tensors (copy the mean and std from previous lesson!)\n",
    "        transforms.Normalize(\n",
    "            mean = [0.4326, 0.4953, 0.3120], std = [0.2178, 0.2214, 0.2091]\n",
    "        )\n",
    "        \n",
    "    ]\n",
    ")\n",
    "\n",
    "print(type(transform_normalized))\n",
    "print(\"-----------------\")\n",
    "print(transform_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset: 8180\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.ImageFolder(root=train_dir, transform= transform_normalized)\n",
    "\n",
    "print('Length of dataset:', len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Train and validation splitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training dataset: 6544\n",
      "Length of validation dataset: 1636\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator()\n",
    "g.manual_seed(42)\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [0.8, 0.2], generator=g)\n",
    "\n",
    "print(\"Length of training dataset:\", len(train_dataset))\n",
    "print(\"Length of validation dataset:\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data is 80.0% of full data\n",
      "Validation data is 20.0% of full data\n"
     ]
    }
   ],
   "source": [
    "length_dataset = len(dataset)\n",
    "length_train = len(train_dataset)\n",
    "length_val = len(val_dataset)\n",
    "\n",
    "percent_train = np.round(100 * length_train / length_dataset, 2)\n",
    "percent_val = np.round(100 * length_val / length_dataset, 2)\n",
    "\n",
    "print(f\"Train data is {percent_train}% of full data\")\n",
    "print(f\"Validation data is {percent_val}% of full data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
